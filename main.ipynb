{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9495e5b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\n",
      " !\"#%&'()*+,-./0123456789:<=>?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[\\]_abcdefghijklmnopqrstuvwxyz{}Ä†Ä‡ÄÄ‘Å Å¡Å¾ÐÐ£Ð°Ð±Ð²Ð³Ð´ÐµÐ·Ð¸ÐºÐ»Ð¼Ð½Ð¾Ð¿Ñ€ÑÑ‚ÑƒÑ…Ñ‡ÑˆÑ’Ñ˜ÑšÑ›â€¦â âœ‹â¤ï»¿ðŸ»ðŸ¼ðŸ½ðŸ‘‹ðŸ‘ŒðŸ‘ðŸ‘½ðŸ’ªðŸ˜€ðŸ˜‚ðŸ˜ƒðŸ˜ðŸ˜ŸðŸ™‚ðŸ™ŒðŸ™ðŸ¤‘ðŸ¤˜ðŸ¤™ðŸ¤ðŸ¤¢ðŸ¤£ðŸ¤®ðŸ¥°ðŸ¥·ðŸ¥¹ðŸ§ ðŸ«‚ðŸ«¶\n",
      "159\n",
      "Step 0: train loss 5.5599, val loss 5.5486\n",
      "Step 1000: train loss 4.2775, val loss 4.2967\n",
      "Step 2000: train loss 3.3423, val loss 3.4014\n",
      "Step 3000: train loss 2.7434, val loss 2.8484\n",
      "Step 4000: train loss 2.4238, val loss 2.5454\n",
      "Step 5000: train loss 2.2727, val loss 2.4024\n",
      "Step 6000: train loss 2.1916, val loss 2.3212\n",
      "Step 7000: train loss 2.1470, val loss 2.2895\n",
      "Step 8000: train loss 2.1150, val loss 2.2614\n",
      "Step 9000: train loss 2.1398, val loss 2.2525\n"
     ]
    }
   ],
   "source": [
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1fa2f11",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'utils' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mutils\u001b[49m\u001b[38;5;241m.\u001b[39mintuition_test(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrivan\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'utils' is not defined"
     ]
    }
   ],
   "source": [
    "utils.intuition_test('trivan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42fd7b29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch.nn import functional as F\n",
    "torch.manual_seed(1111)\n",
    "\n",
    "B, T, C = 4, 8, 2\n",
    "x = torch.randn(B, T, C)\n",
    "\n",
    "# v1\n",
    "xbow = torch.zeros((B, T, C))\n",
    "for b in range (B):\n",
    "    for t in range (T):\n",
    "        xprev = x[b, :t + 1]\n",
    "        xbow[b, t] = torch.mean(xprev, 0)\n",
    "\n",
    "# v2\n",
    "wei = torch.tril(torch.ones(T, T))\n",
    "wei = wei / wei.sum(1, keepdim=True)\n",
    "xbow2 = wei @ x # (B, T, T) @ (B, T, C) -> (B, T, C)\n",
    "\n",
    "# v3\n",
    "tril = torch.tril(torch.ones(T, T))\n",
    "wei = torch.zeros((T, T))\n",
    "wei = wei.masked_fill(tril == 0, float('-inf'))\n",
    "wei = F.softmax(wei, dim=-1)\n",
    "xbow3 = wei @ x\n",
    "\n",
    "torch.allclose(xbow2, xbow3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd12139",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 8, 32])\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "torch.manual_seed(1111)\n",
    "torch.set_printoptions(precision=3)\n",
    "\n",
    "B, T, C = 4, 8, 32\n",
    "x = torch.randn(B, T, C)\n",
    "\n",
    "head_size = 16\n",
    "key = nn.Linear(C, head_size, bias=False)\n",
    "query = nn.Linear(C, head_size, bias=False)\n",
    "value = nn.Linear(C, head_size, bias=False)\n",
    "\n",
    "# The nn.Linear layer is applied independently to each 32-dimensional token vector inside the tensor x\n",
    "# Because the k, q and v are all produced by x, it's called self attention (not cross)\n",
    "k = key(x) #  (4, 8, 16) â€” a 16-dimensional key vector for each token.\n",
    "q = query(x) # (4, 8, 16) â€” a 16-dimensional query vector for each token.\n",
    "v = value(x) # (4, 8, 16) â€” a 16-dimensional query vector for each token.\n",
    "\n",
    "wei = k @ q.transpose(-2, -1)\n",
    "tril = torch.tril(torch.ones(T, T))\n",
    "wei = wei.masked_fill(tril == 0, float('-inf'))\n",
    "wei = wei / Math.sqrt(head_size)\n",
    "wei = F.softmax(wei, dim=-1)\n",
    "\n",
    "out = wei @ v\n",
    "print(out.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7153a6d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27694cdd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
